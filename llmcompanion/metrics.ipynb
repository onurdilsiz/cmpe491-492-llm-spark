{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for: detection_results_all_cases26.12.csv\n",
      "Accuracy:  0.5143939393939394\n",
      "Precision: 1.0\n",
      "Recall:    0.5143939393939394\n",
      "F1 Score:  0.6793396698349174\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = \"detection_results_all_cases26.12.csv\"  # Replace with the correct file path\n",
    "detection_data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure boolean columns are correctly interpreted (if necessary)\n",
    "detection_data['Detection'] = detection_data['Detection'].astype(bool)\n",
    "detection_data['Expected Detection'] = detection_data['Expected Detection'].astype(bool)\n",
    "\n",
    "# Directly use the boolean columns as they are already binary (True = 1, False = 0)\n",
    "y_pred = detection_data['Detection'] # Make sure the column name is correct\n",
    "y_true = detection_data['Expected Detection'] # Make sure the column name is correct\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Metrics for:\", file_path)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:   \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model  Accuracy  Precision    Recall  F1 Score\n",
      "0    gemini-1.0-pro-002  0.336364        1.0  0.336364  0.503401\n",
      "1  gemini-1.5-flash-002  0.612121        1.0  0.612121  0.759398\n",
      "2  gemini-2.0-flash-exp  0.500000        1.0  0.500000  0.666667\n",
      "3    gpt-3.5-turbo-0125  0.609091        1.0  0.609091  0.757062\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = \"detection_results_all_cases26.12.csv\"  # Replace with the correct file path\n",
    "detection_data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure boolean columns are correctly interpreted (if necessary)\n",
    "detection_data['Detection'] = detection_data['Detection'].astype(bool)\n",
    "detection_data['Expected Detection'] = detection_data['Expected Detection'].astype(bool)\n",
    "\n",
    "# Initialize a dictionary to store metrics per model\n",
    "metrics_per_model = []\n",
    "\n",
    "# Group by 'Model' and calculate metrics for each group\n",
    "for model, group in detection_data.groupby('Model'):\n",
    "    y_pred = group['Detection']\n",
    "    y_true = group['Expected Detection']\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    \n",
    "    metrics_per_model.append({\n",
    "        'Model': model,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "metrics_df = pd.DataFrame(metrics_per_model)\n",
    "\n",
    "# Save metrics to a CSV or display them\n",
    "metrics_df.to_csv(\"all_metrics_per_model.csv\", index=False)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
