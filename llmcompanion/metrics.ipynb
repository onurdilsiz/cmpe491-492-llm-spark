{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        TRUE\n",
      "1        TRUE\n",
      "2        TRUE\n",
      "3        TRUE\n",
      "4       FALSE\n",
      "        ...  \n",
      "1315    FALSE\n",
      "1316    FALSE\n",
      "1317    FALSE\n",
      "1318    FALSE\n",
      "1319     TRUE\n",
      "Name: Expected Detection, Length: 1320, dtype: object\n",
      "0       True\n",
      "1       True\n",
      "2       True\n",
      "3       True\n",
      "4       True\n",
      "        ... \n",
      "1315    True\n",
      "1316    True\n",
      "1317    True\n",
      "1318    True\n",
      "1319    True\n",
      "Name: Expected Detection, Length: 1320, dtype: bool\n",
      "Metrics for: detection_results_all_cases26.12.csv\n",
      "Accuracy:  0.5143939393939394\n",
      "Precision: 1.0\n",
      "Recall:    0.5143939393939394\n",
      "F1 Score:  0.6793396698349174\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = \"detection_results_all_cases26.12.csv\"  # Replace with the correct file path\n",
    "detection_data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Directly use the boolean columns as they are already binary (True = 1, False = 0)\n",
    "y_pred = detection_data['Detection'] # Make sure the column name is correct\n",
    "y_true = detection_data['Expected Detection'] # Make sure the column name is correct\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Metrics for:\", file_path)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:   \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'specific_metrics_per_model_whole.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(metrics_per_model)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Save metrics to a CSV or display them\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mmetrics_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspecific_metrics_per_model_whole.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics_df)\n",
      "File \u001b[1;32mc:\\Users\\onurd\\Desktop\\CMPE491\\weeks\\week6\\aiderT\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\onurd\\Desktop\\CMPE491\\weeks\\week6\\aiderT\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\onurd\\Desktop\\CMPE491\\weeks\\week6\\aiderT\\venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\onurd\\Desktop\\CMPE491\\weeks\\week6\\aiderT\\venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\onurd\\Desktop\\CMPE491\\weeks\\week6\\aiderT\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'specific_metrics_per_model_whole.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = \"specific_detection_results.csv\"  # Replace with the correct file path\n",
    "detection_data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Ensure boolean columns are correctly interpreted (if necessary)\n",
    "detection_data['Detection Result'] = detection_data['Detection Result'].astype(bool)\n",
    "detection_data['Expected Result'] = detection_data['Expected Result'].astype(bool)\n",
    "\n",
    "# Initialize a dictionary to store metrics per model\n",
    "metrics_per_model = []\n",
    "\n",
    "# Group by 'Model' and calculate metrics for each group\n",
    "for model, group in detection_data.groupby('Model'):\n",
    "    y_pred = group['Detection Result']\n",
    "    y_true = group['Expected Result']\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    \n",
    "    metrics_per_model.append({\n",
    "        'Model': model,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "metrics_df = pd.DataFrame(metrics_per_model)\n",
    "\n",
    "# Save metrics to a CSV or display them\n",
    "metrics_df.to_csv(\"specific_metrics_per_model_whole.csv\", index=False)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False]\n",
      "[ True False]\n",
      "0        True\n",
      "1       False\n",
      "2        True\n",
      "3        True\n",
      "4       False\n",
      "        ...  \n",
      "1975    False\n",
      "1976     True\n",
      "1977     True\n",
      "1978    False\n",
      "1979     True\n",
      "Name: Detection Result, Length: 1980, dtype: bool\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4       False\n",
      "        ...  \n",
      "1975    False\n",
      "1976    False\n",
      "1977    False\n",
      "1978    False\n",
      "1979     True\n",
      "Name: Expected Result, Length: 1980, dtype: bool\n",
      "\n",
      "Metrics Per Case and Model:\n",
      "                       Case                       Model  Accuracy  Precision  \\\n",
      "0             Avoiding UDFs          gemini-1.0-pro-002  0.742424   0.705882   \n",
      "1             Avoiding UDFs        gemini-1.5-flash-002  0.787879   0.656250   \n",
      "2             Avoiding UDFs        gemini-2.0-flash-exp  0.772727   0.655172   \n",
      "3             Avoiding UDFs          gpt-3.5-turbo-0125  0.757576   0.700000   \n",
      "4             Avoiding UDFs                      gpt-4o  0.787879   0.777778   \n",
      "5             Avoiding UDFs  llama-3.1-8b-instruct-maas  0.742424   0.606061   \n",
      "6   Coalesce vs Repartition          gemini-1.0-pro-002  0.681818   0.535714   \n",
      "7   Coalesce vs Repartition        gemini-1.5-flash-002  0.803030   0.708333   \n",
      "8   Coalesce vs Repartition        gemini-2.0-flash-exp  0.818182   0.739130   \n",
      "9   Coalesce vs Repartition          gpt-3.5-turbo-0125  0.469697   0.380000   \n",
      "10  Coalesce vs Repartition                      gpt-4o  0.818182   0.739130   \n",
      "11  Coalesce vs Repartition  llama-3.1-8b-instruct-maas  0.621212   0.473684   \n",
      "12     Map vs MapPartitions          gemini-1.0-pro-002  0.590909   0.647059   \n",
      "13     Map vs MapPartitions        gemini-1.5-flash-002  0.787879   0.750000   \n",
      "14     Map vs MapPartitions        gemini-2.0-flash-exp  0.772727   0.840000   \n",
      "15     Map vs MapPartitions          gpt-3.5-turbo-0125  0.560606   0.534884   \n",
      "16     Map vs MapPartitions                      gpt-4o  0.833333   0.862069   \n",
      "17     Map vs MapPartitions  llama-3.1-8b-instruct-maas  0.666667   0.708333   \n",
      "18         RDD vs DataFrame          gemini-1.0-pro-002  0.909091   0.945946   \n",
      "19         RDD vs DataFrame        gemini-1.5-flash-002  0.818182   0.787234   \n",
      "20         RDD vs DataFrame        gemini-2.0-flash-exp  0.939394   0.926829   \n",
      "21         RDD vs DataFrame          gpt-3.5-turbo-0125  0.787879   0.777778   \n",
      "22         RDD vs DataFrame                      gpt-4o  0.969697   0.974359   \n",
      "23         RDD vs DataFrame  llama-3.1-8b-instruct-maas  0.500000   0.560000   \n",
      "24  Serialized Data Formats          gemini-1.0-pro-002  0.318182   0.500000   \n",
      "25  Serialized Data Formats        gemini-1.5-flash-002  0.666667   0.682540   \n",
      "26  Serialized Data Formats        gemini-2.0-flash-exp  0.636364   0.723404   \n",
      "27  Serialized Data Formats          gpt-3.5-turbo-0125  0.545455   0.674419   \n",
      "28  Serialized Data Formats                      gpt-4o  0.590909   0.725000   \n",
      "29  Serialized Data Formats  llama-3.1-8b-instruct-maas  0.636364   0.756098   \n",
      "\n",
      "      Recall  F1 Score  \n",
      "0   0.500000  0.585366  \n",
      "1   0.875000  0.750000  \n",
      "2   0.791667  0.716981  \n",
      "3   0.583333  0.636364  \n",
      "4   0.583333  0.666667  \n",
      "5   0.833333  0.701754  \n",
      "6   0.652174  0.588235  \n",
      "7   0.739130  0.723404  \n",
      "8   0.739130  0.739130  \n",
      "9   0.826087  0.520548  \n",
      "10  0.739130  0.739130  \n",
      "11  0.782609  0.590164  \n",
      "12  0.343750  0.448980  \n",
      "13  0.843750  0.794118  \n",
      "14  0.656250  0.736842  \n",
      "15  0.718750  0.613333  \n",
      "16  0.781250  0.819672  \n",
      "17  0.531250  0.607143  \n",
      "18  0.897436  0.921053  \n",
      "19  0.948718  0.860465  \n",
      "20  0.974359  0.950000  \n",
      "21  0.897436  0.833333  \n",
      "22  0.974359  0.974359  \n",
      "23  0.717949  0.629213  \n",
      "24  0.133333  0.210526  \n",
      "25  0.955556  0.796296  \n",
      "26  0.755556  0.739130  \n",
      "27  0.644444  0.659091  \n",
      "28  0.644444  0.682353  \n",
      "29  0.688889  0.720930  \n",
      "\n",
      "Metrics Per Case:\n",
      "                      Case  Accuracy  Precision    Recall  F1 Score\n",
      "0            Avoiding UDFs  0.765152   0.671141  0.694444  0.682594\n",
      "1  Coalesce vs Repartition  0.702020   0.553763  0.746377  0.635802\n",
      "2     Map vs MapPartitions  0.702020   0.712644  0.645833  0.677596\n",
      "3         RDD vs DataFrame  0.820707   0.814672  0.901709  0.855984\n",
      "4  Serialized Data Formats  0.565657   0.699187  0.637037  0.666667\n",
      "\n",
      "Metrics Per Model:\n",
      "                        Model  Accuracy  Precision    Recall  F1 Score\n",
      "0          gemini-1.0-pro-002  0.648485   0.711712  0.484663  0.576642\n",
      "1        gemini-1.5-flash-002  0.772727   0.717822  0.889571  0.794521\n",
      "2        gemini-2.0-flash-exp  0.787879   0.781818  0.791411  0.786585\n",
      "3          gpt-3.5-turbo-0125  0.624242   0.597015  0.736196  0.659341\n",
      "4                      gpt-4o  0.800000   0.825503  0.754601  0.788462\n",
      "5  llama-3.1-8b-instruct-maas  0.633333   0.612903  0.699387  0.653295\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = \"all_case_detection_results.csv\"  # Replace with the correct file path\n",
    "detection_data = pd.read_csv(file_path)\n",
    "print(detection_data['Detection Result'].unique())\n",
    "print(detection_data['Expected Result'].unique())\n",
    "\n",
    "\n",
    "# Ensure boolean columns are correctly interpreted\n",
    "# Map strings to boolean values\n",
    "detection_data['Detection Result'] = detection_data['Detection Result'].astype(bool)\n",
    "detection_data['Expected Result'] = detection_data['Expected Result'].astype(bool)\n",
    "\n",
    "\n",
    "\n",
    "print(detection_data['Detection Result'])\n",
    "print(detection_data['Expected Result'])\n",
    "\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "metrics_per_case_model = []\n",
    "metrics_per_case = []\n",
    "metrics_per_model = []\n",
    "\n",
    "# Group by 'Case' and 'Model' and calculate metrics\n",
    "for (case, model), group in detection_data.groupby(['Case', 'Model']):\n",
    "    y_pred = group['Detection Result']\n",
    "    y_true = group['Expected Result']\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    \n",
    "    metrics_per_case_model.append({\n",
    "        'Case': case,\n",
    "        'Model': model,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Group by 'Case' and calculate metrics\n",
    "for case, group in detection_data.groupby('Case'):\n",
    "    y_pred = group['Detection Result']\n",
    "    y_true = group['Expected Result']\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    \n",
    "    metrics_per_case.append({\n",
    "        'Case': case,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Group by 'Model' and calculate metrics\n",
    "for model, group in detection_data.groupby('Model'):\n",
    "    y_pred = group['Detection Result']\n",
    "    y_true = group['Expected Result']\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    \n",
    "    metrics_per_model.append({\n",
    "        'Model': model,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Convert the results to DataFrames\n",
    "case_model_metrics_df = pd.DataFrame(metrics_per_case_model)\n",
    "case_metrics_df = pd.DataFrame(metrics_per_case)\n",
    "model_metrics_df = pd.DataFrame(metrics_per_model)\n",
    "\n",
    "# Save metrics to CSV files\n",
    "case_model_metrics_df.to_csv(\"whole_metrics_per_case_model.csv\", index=False)\n",
    "case_metrics_df.to_csv(\"whole_metrics_per_case.csv\", index=False)\n",
    "model_metrics_df.to_csv(\"whole_metrics_per_model.csv\", index=False)\n",
    "\n",
    "# Print metrics for immediate review\n",
    "print(\"\\nMetrics Per Case and Model:\")\n",
    "print(case_model_metrics_df)\n",
    "print(\"\\nMetrics Per Case:\")\n",
    "print(case_metrics_df)\n",
    "print(\"\\nMetrics Per Model:\")\n",
    "print(model_metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
